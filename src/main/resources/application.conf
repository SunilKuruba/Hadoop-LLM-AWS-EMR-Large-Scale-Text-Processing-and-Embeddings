# Hadoop cluster configuration
hadoop {
  fileSystem {
    local = "hdfs://localhost:9000"    # HDFS NameNode URL
    test = ""
    prod = ""
  }
  numReducer = 1                            # number of reducers
  maxSplitSize = 268435456                  # 256 MB
  tokenizer.jobName = "tokenizer"
}

# Input and Output paths
io {
  inputdir {
    local = "/input/tiny_input.txt"            # HDFS input directory
    test = "src/test/resources/input"
    prod = "s3://cloud-computing-441/homework-1/input/tiny_input.txt"
   }
  outputdir {
      local = "/output/"            # HDFS output directory
      test = "src/test/resources/output/"
      prod = "s3://cloud-computing-441/homework-1/output/"
     }
}

# Embeddding Job configuration
embeddingJob {
    jobName = "Embedder"
    vocabSize = 100000
    embeddingDim = 100
    numEpochs = 100
}