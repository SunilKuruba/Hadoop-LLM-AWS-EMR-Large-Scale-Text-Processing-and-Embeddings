# application.conf for Hadoop MapReduce program

# Hadoop cluster configuration
hadoop {
  fileSystem {
    local = "hdfs://localhost:9000"    # HDFS NameNode URL
    test = ""
    prod = ""
  }
  jobtracker = "localhost:54311"             # JobTracker location
  replication = 3                           # HDFS replication factor
  blockSize = 134217728                     # Block size in bytes (128 MB by default)
  tokenizer.jobName = "tokenizer"
}

# Input and Output paths
io {
  inputdir {
    local = "/input/tiny_input.txt"            # HDFS input directory
    test = "src/test/resources/input"
    prod = "s3://cloud-computing-441/homework-1/input/tiny_input.txt"
   }
  outputdir {
      local = "/output/"            # HDFS output directory
      test = "src/test/resources/output/"
      prod = "s3://cloud-computing-441/homework-1/output/"
     }
}

#Embeddding Job configuration
embeddingJob {
    jobName = "Embedder"
    vocabSize = 100000
    embeddingDim = 5
    testNumEpochs = 1
    prodNumEpochs = 100
}